# Local Search and Optimization Problems
- In many optimizaiton problems, path to goal is irrelevant; the goal state iteself is the solution
- Just need to find a configuration that satisfies constraints
- For these types of problems we would use a *local search algorithm*
- Keep a single "current" state, try to improve it
	- Greedy
- Example: n-Queens problem


# Local Search in Continuous spaces
### Hill Climbing
- "Like climbing Everest in thick fog w/ amnesia"
- No memory of path is stored
- No fringe is kept
- More efficient spacewise, and computation-wise
- Not complete or optimal
	- Problem: depending on intial state, can get stuck in local maxima
		![[Pasted image 20230227143713.png]]

### Simulated Annealing
- Escape local maxima by allowing downhill moves
	- But make those moves rarer as time goes on
![[Pasted image 20230301135208.png]]
- Theoretical guarantee that if T is decreased slowly enough, then it will converge to the optimal state

### Local Beam Search
- Keep track of k states rather than just one
- Start with k randomly generated states
- Select from best k successors, unless at goal state

### Genetic Algorithm
![[Pasted image 20230301135702.png]]
- A successor state is generated by combining two parent states 
- Start with k randomly generated states (population) 
- A state is represented as a string over a finite alphabet (often a string of 0s and 1s) 
- Evaluation function (fitness function). Higher values for better states. 
- Produce the next generation of states by selection, crossover, and mutation

